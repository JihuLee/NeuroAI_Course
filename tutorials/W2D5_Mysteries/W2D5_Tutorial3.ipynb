{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89a00b06-154b-4aaf-8bee-b96a675406b5",
   "metadata": {
    "execution": {}
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/neuromatch/NeuroAI_Course/blob/main/tutorials/W2D5_Mysteries/student/W2D5_Tutorial1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> &nbsp; <a href=\"https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/neuromatch/NeuroAI_Course/main/tutorials/W2D5_Mysteries/student/W2D5_Tutorial1.ipynb\"  target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open in Kaggle\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ed61a3-87d2-4e76-83f6-4b786c101af2",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# (Bonus) Tutorial 3: Consciousness (Extended)\n",
    "\n",
    "**Week 2, Day 5: Mysteries**\n",
    "\n",
    "**By Neuromatch Academy**\n",
    "\n",
    "__Content creators:__ Steve Fleming, Guillaume Dumas, Samuele Bolotta, Juan David Vargas, Hakwan Lau, Anil Seth, Megan Peters\n",
    "\n",
    "__Content reviewers:__ Samuele Bolotta, Lily Chamakura, RyeongKyung Yoon, Yizhou Chen, Ruiyi Zhang, Patrick Mineault, Alex Murphy\n",
    "\n",
    "__Production editors:__ Konstantine Tsafatinos, Ella Batty, Spiros Chavlis, Samuele Bolotta, Hlib Solodzhuk, Patrick Mineault, Alex Murphy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7861818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & content variables for the day\n",
    "assert 1 == 0, \"Please run this script with the correct day number.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de910a5b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Introduction\n",
    "\n",
    "This bonus tutorial extends a lot of the content that was covered in Tutorial 1 based around the theme of Consciousness. At the end of Section 2. We discussed and implemented a lot of ideas around first-order models and we briefly mentioned second-order models. In this tutorial, we're going to actually develop some ideas and model the effects of blindsight, the phenomenon we introduced earlier on today, where patients have no conscious experience of sight but are able to navigate around objects (showing that their brains are processing sensory information, but it doesn't reach the level of subjective experience). We first introduce the coding of the first-order model, followed by the second-order model. Then we show you some ways to plot the results from these models.\n",
    "\n",
    "After this we end on some further high-level thoughts on the theme of consciousness. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dd7488-6558-4022-8541-22765f2967c6",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Section 1: Train a First-Order Network\n",
    "\n",
    "This section invites you to engage with a straightforward, auto-generated dataset on blindsight, originally introduced by [Pasquali et al. in 2010](https://www.sciencedirect.com/science/article/abs/pii/S0010027710001794). Blindsight is a fascinating condition where individuals who are cortically blind due to damage in their primary visual cortex can still respond to visual stimuli without conscious perception. This intriguing phenomenon underscores the intricate nature of sensory processing and the brain's ability to process information without conscious awareness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c79b0a2-8e12-44ea-a685-bba788f6685d",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Visualize the autogenerated data\n",
    "factor=2\n",
    "initialize_global()\n",
    "set_pre, _ = create_patterns(0,factor)\n",
    "plot_signal_max_and_indicator(set_pre.detach().cpu(), \"Example - Pre training dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff70408-8662-43f5-b930-fc2a6ffca323",
   "metadata": {
    "execution": {}
   },
   "source": [
    "The pre-training dataset for the network consisted of 200 patterns. These were evenly divided: half were purely noise (with unit activations randomly chosen between 0.0 and 0.02), and the other half represented potential stimuli. In the stimulus patterns, 99 out of 100 units had activations ranging between 0.0 and 0.02, with one unique unit having an activation between 0.0 and 1.0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f45662a-08b4-44a4-89e1-200fc0c9cddb",
   "metadata": {
    "execution": {}
   },
   "source": [
    "**Testing patterns**\n",
    "\n",
    "As we have seen before, the network underwent evaluations under three distinct conditions, each modifying the signal-to-noise ratio in a unique way to explore different degrees and types of blindness.\n",
    "\n",
    "Suprathreshold stimulus condition: here, the network was exposed to the identical set of 200 patterns used during pre-training, testing the network's response to familiar inputs.\n",
    "\n",
    "Subthreshold stimulus condition (blindsight simulation): this condition aimed to mimic blindsight. It was achieved by introducing a slight noise increment (+0.0012) to every input of the first-order network, barring the one designated as the stimulus. This setup tested the network's ability to discern faint signals amidst noise.\n",
    "\n",
    "Low vision condition: to simulate low vision, the activation levels of the stimuli were reduced. Unlike the range from 0.0 to 1.0 used in pre-training, the stimuli's activation levels were adjusted to span from 0.0 to 0.3. This condition examined the network's capability to recognize stimuli with diminished intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db58d78b-17d8-4651-801a-f06e568a7322",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "factor=2\n",
    "# Compare your results with the patterns generate below\n",
    "set_1, _ = create_patterns(0,factor)\n",
    "set_2, _ = create_patterns(1,factor)\n",
    "set_3, _ = create_patterns(2,factor)\n",
    "\n",
    "# Plot\n",
    "plot_signal_max_and_indicator(set_1.detach().cpu(), \"Suprathreshold dataset\")\n",
    "plot_signal_max_and_indicator(set_2.detach().cpu(), \"Subthreshold dataset\")\n",
    "plot_signal_max_and_indicator(set_3.detach().cpu(), \"Low Vision dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5c13e0-75e8-45c2-b1be-70496041364b",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Coding Exercise 1: Building a network for a blindsight situation\n",
    "\n",
    "In this activity, we'll construct a neural network model using our auto-generated dataset, focusing on blindsight scenarios. The model will primarily consist of fully connected layers, establishing a straightforward, first-order network. The aim here is to assess the basic network's performance.\n",
    "\n",
    "**Steps to follow**\n",
    "\n",
    "1. Examine the network architecture: understand the structure of the neural network you're about to work with.\n",
    "2. Visualize loss metrics: observe and analyze the network's performance during pre-training by visualizing the loss over epochs.\n",
    "3. Evaluate the model: use the provided code snippets to calculate and interpret the model's accuracy, recall, and F1-score, giving you insight into the network's capabilities.\n",
    "\n",
    "**Understanding the process**\n",
    "\n",
    "The goal is to gain a thorough comprehension of the network's architecture and to interpret the pre-training results visually. This will provide a clearer picture of the model's potential and limitations.\n",
    "\n",
    "The network is designed as a backpropagation autoassociator. It features a 100-unit input layer, directly linked to a 40-unit hidden layer, which in turn connects to a 100-unit output layer. Initial connection weights are set within the range of -1.0 to 1.0 for the first-order network. To mitigate overfitting, dropout is employed within the network architecture. The architecture includes a configurable activation function. This flexibility allows for adjustments and tuning in Activity 3, aiming for optimal model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d0bcaf-8b49-4e35-b0d2-1b9dcc98b182",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "class FirstOrderNetwork(nn.Module):\n",
    "    def __init__(self, hidden_units, data_factor, use_gelu):\n",
    "        \"\"\"\n",
    "        Initializes the FirstOrderNetwork with specific configurations.\n",
    "\n",
    "        Parameters:\n",
    "        - hidden_units (int): The number of units in the hidden layer.\n",
    "        - data_factor (int): Factor to scale the amount of data processed.\n",
    "                             A factor of 1 indicates the default data amount,\n",
    "                             while 10 indicates 10 times the default amount.\n",
    "        - use_gelu (bool): Flag to use GELU (True) or ReLU (False) as the activation function.\n",
    "        \"\"\"\n",
    "        super(FirstOrderNetwork, self).__init__()\n",
    "\n",
    "        # Define the encoder, hidden, and decoder layers with specified units\n",
    "\n",
    "        self.fc1 = nn.Linear(100, hidden_units, bias = False) # Encoder\n",
    "        self.hidden= nn.Linear(hidden_units, hidden_units, bias = False) # Hidden\n",
    "        self.fc2 = nn.Linear(hidden_units, 100, bias = False) # Decoder\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "        # Dropout layer to prevent overfitting\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        # Set the data factor\n",
    "        self.data_factor = data_factor\n",
    "\n",
    "        # Other activation functions for various purposes\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "        # Initialize network weights\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        \"\"\"Initializes weights of the encoder, hidden, and decoder layers uniformly.\"\"\"\n",
    "        init.uniform_(self.fc1.weight, -1.0, 1.0)\n",
    "\n",
    "        init.uniform_(self.fc2.weight, -1.0, 1.0)\n",
    "        init.uniform_(self.hidden.weight, -1.0, 1.0)\n",
    "\n",
    "    def encoder(self, x):\n",
    "      h1 = self.dropout(self.relu(self.fc1(x.view(-1, 100))))\n",
    "      return h1\n",
    "\n",
    "    def decoder(self,z):\n",
    "      #h2 = self.relu(self.hidden(z))\n",
    "      h2 = self.sigmoid(self.fc2(z))\n",
    "      return h2\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "      \"\"\"\n",
    "      Defines the forward pass through the network.\n",
    "\n",
    "      Parameters:\n",
    "      - x (Tensor): The input tensor to the network.\n",
    "\n",
    "      Returns:\n",
    "      - Tensor: The output of the network after passing through the layers and activations.\n",
    "      \"\"\"\n",
    "      h1 = self.encoder(x)\n",
    "      h2 = self.decoder(h1)\n",
    "\n",
    "      return h1 , h2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e07f1a-540b-4bfa-8e9b-f114319f1f96",
   "metadata": {
    "execution": {}
   },
   "source": [
    "For now, we will train the first-order network only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfade3d-6385-459c-8f07-e3017264455a",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Define the architecture, optimizers, loss functions, and schedulers for pre training\n",
    "# Hyperparameters\n",
    "\n",
    "# Hyperparameters\n",
    "global optimizer ,n_epochs , learning_rate_1\n",
    "learning_rate_1 = 0.5\n",
    "n_epochs = 100\n",
    "optimizer=\"ADAMAX\"\n",
    "hidden=40\n",
    "factor=2\n",
    "gelu=False\n",
    "gam=0.98\n",
    "meta=True\n",
    "stepsize=25\n",
    "initialize_global()\n",
    "\n",
    "\n",
    "# Networks instantiation\n",
    "first_order_network = FirstOrderNetwork(hidden,factor,gelu).to(device)\n",
    "second_order_network = SecondOrderNetwork(gelu).to(device) # We define it, but won't use it until activity 3\n",
    "\n",
    "# Loss function\n",
    "criterion_1 = CAE_loss\n",
    "\n",
    "# Optimizer\n",
    "optimizer_1 = optim.Adamax(first_order_network.parameters(), lr=learning_rate_1)\n",
    "\n",
    "# Learning rate schedulers\n",
    "scheduler_1 = StepLR(optimizer_1, step_size=stepsize, gamma=gam)\n",
    "\n",
    "max_values_output_first_order = []\n",
    "max_indices_output_first_order = []\n",
    "max_values_patterns_tensor = []\n",
    "max_indices_patterns_tensor = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "    # Generate training patterns and targets for each epoch.\n",
    "    patterns_tensor, stim_present_tensor, stim_absent_tensor, order_2_tensor = generate_patterns(patterns_number, num_units,factor, 0)\n",
    "\n",
    "    # Forward pass through the first-order network\n",
    "    hidden_representation , output_first_order = first_order_network(patterns_tensor)\n",
    "\n",
    "    output_first_order=output_first_order.requires_grad_(True)\n",
    "\n",
    "    # Skip computations for the second-order network\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Potentially forward pass through the second-order network without tracking gradients\n",
    "        output_second_order = second_order_network(patterns_tensor, output_first_order)\n",
    "\n",
    "    # Calculate the loss for the first-order network (accuracy of stimulus representation)\n",
    "    W = first_order_network.state_dict()['fc1.weight']\n",
    "    loss_1 = criterion_1( W, stim_present_tensor.view(-1, 100), output_first_order,\n",
    "                        hidden_representation, lam )\n",
    "    # Backpropagate the first-order network's loss\n",
    "    loss_1.backward()\n",
    "\n",
    "    # Update first-order network weights\n",
    "    optimizer_1.step()\n",
    "\n",
    "    # Reset first-order optimizer gradients to zero for the next iteration\n",
    "\n",
    "    # Update the first-order scheduler\n",
    "    scheduler_1.step()\n",
    "\n",
    "    epoch_1_order[epoch] = loss_1.item()\n",
    "\n",
    "    # Get max values and indices for output_first_order\n",
    "    max_vals_out, max_inds_out = torch.max(output_first_order[100:], dim=1)\n",
    "    max_inds_out[max_vals_out == 0] = 0\n",
    "    max_values_output_first_order.append(max_vals_out.tolist())\n",
    "    max_indices_output_first_order.append(max_inds_out.tolist())\n",
    "\n",
    "    # Get max values and indices for patterns_tensor\n",
    "    max_vals_pat, max_inds_pat = torch.max(patterns_tensor[100:], dim=1)\n",
    "    max_inds_pat[max_vals_pat == 0] = 0\n",
    "    max_values_patterns_tensor.append(max_vals_pat.tolist())\n",
    "    max_indices_patterns_tensor.append(max_inds_pat.tolist())\n",
    "\n",
    "\n",
    "max_values_indices = (max_values_output_first_order[-1],\n",
    "            max_indices_output_first_order[-1],\n",
    "            max_values_patterns_tensor[-1],\n",
    "            max_indices_patterns_tensor[-1])\n",
    "\n",
    "\n",
    "# Plot training loss curve\n",
    "pre_train_plots(epoch_1_order, epoch_2_order, \"1st & 2nd Order Networks\" , max_value_indices )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7d1ce9-da1b-4f78-b388-47bfcd50c6dd",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Testing under 3 Blindsight Conditions\n",
    "\n",
    "We will now use the testing auto-generated datasets from activity 1 to test the network's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2affe162-f4d9-495f-862a-65b0f50ca5ef",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "results_seed=[]\n",
    "discrimination_seed=[]\n",
    "\n",
    "# Prepare networks for testing by calling the configuration function\n",
    "testing_patterns, n_samples, loaded_model, loaded_model_2 = config_training(first_order_network, second_order_network, hidden, factor, gelu)\n",
    "\n",
    "# Perform testing using the defined function and plot the results\n",
    "f1_scores_wager, mse_losses_indices , mse_losses_values , discrimination_performances, results_for_plotting = testing(testing_patterns, n_samples, loaded_model, loaded_model_2,factor)\n",
    "\n",
    "results_seed.append(results_for_plotting)\n",
    "discrimination_seed.append(discrimination_performances)\n",
    "# Assuming plot_testing is defined, call it to display results\n",
    "plot_testing(results_seed,discrimination_seed,  1, \"Seed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d18302e-4657-4732-b6ef-f7439d2bb2fd",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_First_order_network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96579a08-3c95-4dfe-9908-fabe1bb146d0",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Section 2: Train a Second-Order network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caac41bc-5a93-43bf-aede-7c1e87e83fbd",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Having previously examined the first-order network, we now switch to the second-order network, described in more detail back in Tutorial 1 (please revisit the text and video content there if you need to recap the concepts or want to refresh your understanding of the difference between these models )\n",
    "To study this, we use a simulated dataset that mimics the conditions of blindsight. This dataset contains 400 patterns, equally split between two types:\n",
    "\n",
    "- **Random noise patterns** consist of low activations ranging between 0.0 and 0.02.\n",
    "- **Designed stimulus patterns** - each pattern includes one unit that shows a higher activation level, varying between 0.0 and 1.0.\n",
    "\n",
    "This dataset allows us to test hypotheses concerning how sensory processing and network responses adapt under different conditions of visual impairment.\n",
    "\n",
    "We have three main testing scenarios, each designed to alter the signal-to-noise ratio to simulate different levels of visual impairment:\n",
    "\n",
    "- **Suprathreshold stimulus condition**: here, the network is tested against familiar patterns used during training to assess its response to known stimuli.\n",
    "- **Subthreshold stimulus condition**: this condition slightly increases the noise level, akin to actual blindsight conditions, testing the network's capability to discern subtle signals.\n",
    "- **Low vision condition**: the intensity of stimuli is decreased to evaluate how well the network performs with significantly reduced sensory input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b549db9-e8b0-4c49-89d2-b7324b3a4ed1",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "factor=2\n",
    "\n",
    "initialize_global()\n",
    "set_1, _ = create_patterns(0,factor)\n",
    "set_2, _ = create_patterns(1,factor)\n",
    "set_3, _ = create_patterns(2,factor)\n",
    "\n",
    "# Plot\n",
    "plot_signal_max_and_indicator(set_1.detach().cpu(), \"Suprathreshold dataset\")\n",
    "plot_signal_max_and_indicator(set_2.detach().cpu(), \"Subthreshold dataset\")\n",
    "plot_signal_max_and_indicator(set_3.detach().cpu(), \"Low Vision dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a91af5-c498-429d-a407-afa66d7444db",
   "metadata": {
    "execution": {}
   },
   "source": [
    "The first-order network model lays the groundwork for our experiments and is structured as follows:\n",
    "\n",
    "- Input layer: consists of 100 units representing either noise or stimulus patterns.\n",
    "- Hidden layer: includes a 40-unit layer tasked with processing the inputs.\n",
    "- Output layer: comprises 100 units where the responses to stimuli are recorded.\n",
    "- Dropout and activation: includes dropout layers to prevent overfitting and a temperature-controlled activation function to fine-tune response sharpness.\n",
    "\n",
    "The primary aim of the first-order network is to accurately capture and react to the input patterns, setting a baseline for comparison with more complex models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768e074d-1a07-4f3e-8a5d-de31849e7730",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Coding Exercise 2: Developing a Second-Order Network\n",
    "\n",
    "Your task is to expand upon the first-order network by integrating a second-order network that incorporates a metacognitive layer assessing the predictions of the first-order network. This metacognitive layer introduces a wagering mechanism, wherein the network \"bets\" on its confidence in its predictions. \n",
    "\n",
    "- The first-order network is designed as an autoencoder, a type of neural network trained to reconstruct the input stimulus. The autoencoder consists of an encoder that compresses the input into a latent representation and a decoder that reconstructs the input from this representation.\n",
    "- The second-order network, or metacognitive layer, operates by examining the difference (delta) between the original input and the output generated by the autoencoder. This difference provides insight into the reconstruction error, which is a measure of how accurately the autoencoder has learned to replicate the input data. By evaluating this reconstruction error, the second-order network can make a judgement about the certainty of the first-order network's predictions.\n",
    "\n",
    "These are the steps for completion:\n",
    "\n",
    "1. Architectural development: grasp the underlying principles of a second-order network and complete the architectural code.\n",
    "2. Performance evaluation: visualize training losses and test the model using provided code, assessing its initial performance.\n",
    "3. Model fine-tuning: leveraging the provided training function, experiment with fine-tuning the model to enhance its accuracy and efficiency.\n",
    "\n",
    "The second-order network is structured as a feedforward backpropagation network.\n",
    "\n",
    "- Input layer: comprises a 100-unit comparison matrix. This matrix quantifies the discrepancy between each corresponding pair of input and output units from the first-order network. For example, if an input unit and its corresponding output unit have activations of 0.6 and 0.7, respectively, the comparison unit's activation would be -0.1. This setup essentially encodes the prediction error of the first-order network's outputs as an input pattern for the second-order network.\n",
    "- Output layer: consists of two units representing \"high\" and \"low\" wagers, indicating the network's confidence in its predictions. The initial weights for these output units range between 0.0 and 0.1.\n",
    "- Comparator weights: set to 1.0 for connections from the first-order input layer to the comparison matrix, and -1.0 for connections from the first-order output layer. This configuration emphasizes the differential error as a critical input for the second-order decision-making process.\n",
    "\n",
    "The second-order network's novel approach uses the error generated by the first-order network as a direct input for making decisions—specifically, wagering on the confidence of its outputs. This methodology reflects a metacognitive layer of processing, akin to evaluating one's confidence in their answers or predictions.\n",
    "\n",
    "By exploring these adjustments, you can optimize the network's functionality, making it a powerful tool for understanding and simulating complex cognitive phenomena like blindsight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c37e357-e5e6-40b2-8507-f83161f5d85f",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "class SecondOrderNetwork(nn.Module):\n",
    "    def __init__(self, use_gelu):\n",
    "        super(SecondOrderNetwork, self).__init__()\n",
    "        # Define a linear layer for comparing the difference between input and output of the first-order network\n",
    "        self.comparison_layer = nn.Linear(100, 100)\n",
    "\n",
    "        # Linear layer for determining wagers, mapping from 100 features to a single output\n",
    "        self.wager = nn.Linear(100, 1)\n",
    "\n",
    "        # Dropout layer to prevent overfitting by randomly setting input units to 0 with a probability of 0.5 during training\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        # Select activation function based on the `use_gelu` flag\n",
    "        self.activation = torch.relu\n",
    "\n",
    "        # Additional activation functions for potential use in network operations\n",
    "        self.sigmoid = torch.sigmoid\n",
    "\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "        # Initialize the weights of the network\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        # Uniformly initialize weights for the comparison and wager layers\n",
    "        init.uniform_(self.comparison_layer.weight, -1.0, 1.0)\n",
    "        init.uniform_(self.wager.weight, 0.0, 0.1)\n",
    "\n",
    "    def _init_weights(self):\n",
    "        # Uniformly initialize weights for the comparison and wager layers\n",
    "        init.uniform_(self.comparison_layer.weight, -1.0, 1.0)\n",
    "        init.uniform_(self.wager.weight, 0.0, 0.1)\n",
    "\n",
    "    def forward(self, first_order_input, first_order_output):\n",
    "        ############################################################\n",
    "        # Fill in the wager value\n",
    "        # Applying dropout and sigmoid activation to the output of the wager layer\n",
    "        raise NotImplementedError(\"Student exercise\")\n",
    "        ############################################################\n",
    "\n",
    "        # Calculate the difference between the first-order input and output\n",
    "        comparison_matrix = first_order_input - first_order_output\n",
    "\n",
    "        #Another option is to directly calculate the per unit MSE to use as input for the comparator matrix\n",
    "        #comparison_matrix = nn.MSELoss(reduction='none')(first_order_output, first_order_input)\n",
    "\n",
    "        # Pass the difference through the comparison layer and apply the chosen activation function\n",
    "        comparison_out=self.dropout(self.activation(self.comparison_layer(comparison_matrix)))\n",
    "\n",
    "        # Calculate the wager value, applying dropout and sigmoid activation to the output of the wager layer\n",
    "        wager = ...\n",
    "\n",
    "        return wager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d931cb5-a87a-48be-8760-79512b9d88f7",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# to_remove solution\n",
    "class SecondOrderNetwork(nn.Module):\n",
    "    def __init__(self, use_gelu):\n",
    "        super(SecondOrderNetwork, self).__init__()\n",
    "        # Define a linear layer for comparing the difference between input and output of the first-order network\n",
    "        self.comparison_layer = nn.Linear(100, 100)\n",
    "\n",
    "        # Linear layer for determining wagers, mapping from 100 features to a single output\n",
    "        self.wager = nn.Linear(100, 1)\n",
    "\n",
    "        # Dropout layer to prevent overfitting by randomly setting input units to 0 with a probability of 0.5 during training\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        # Select activation function based on the `use_gelu` flag\n",
    "        self.activation = torch.relu\n",
    "\n",
    "        # Additional activation functions for potential use in network operations\n",
    "        self.sigmoid = torch.sigmoid\n",
    "\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "        # Initialize the weights of the network\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        # Uniformly initialize weights for the comparison and wager layers\n",
    "        init.uniform_(self.comparison_layer.weight, -1.0, 1.0)\n",
    "        init.uniform_(self.wager.weight, 0.0, 0.1)\n",
    "\n",
    "    def forward(self, first_order_input, first_order_output):\n",
    "        # Calculate the difference between the first-order input and output\n",
    "        comparison_matrix = first_order_input - first_order_output\n",
    "\n",
    "        #Another option is to directly calculate the per unit MSE to use as input for the comparator matrix\n",
    "        #comparison_matrix = nn.MSELoss(reduction='none')(first_order_output, first_order_input)\n",
    "\n",
    "        # Pass the difference through the comparison layer and apply the chosen activation function\n",
    "        comparison_out=self.dropout(self.activation(self.comparison_layer(comparison_matrix)))\n",
    "\n",
    "        # Calculate the wager value, applying dropout and sigmoid activation to the output of the wager layer\n",
    "        wager = self.sigmoid(self.wager(comparison_out))\n",
    "\n",
    "        return wager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736319ec-2a17-4d80-bb04-b9507ba5db5d",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Second_Order_Network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45208df8-1cb6-4669-a968-2c5157e8522e",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "hidden=40\n",
    "factor=2\n",
    "gelu=False\n",
    "gam=0.98\n",
    "meta=True\n",
    "stepsize=25\n",
    "\n",
    "initialize_global()\n",
    "\n",
    "# First order network instantiation\n",
    "first_order_network = FirstOrderNetwork(hidden, factor, gelu).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947c8550-a40d-43aa-bfd6-1eb8cead339f",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "def pre_train(first_order_network, second_order_network, criterion_1,  criterion_2, optimizer_1, optimizer_2, scheduler_1, scheduler_2, factor, meta):\n",
    "    \"\"\"\n",
    "    Conducts pre-training for first-order and second-order networks.\n",
    "\n",
    "    Parameters:\n",
    "    - first_order_network (torch.nn.Module): Network for basic input-output mapping.\n",
    "    - second_order_network (torch.nn.Module): Network for decision-making based on the first network's output.\n",
    "    - criterion_1, criterion_2 (torch.nn): Loss functions for the respective networks.\n",
    "    - optimizer_1, optimizer_2 (torch.optim): Optimizers for the respective networks.\n",
    "    - scheduler_1, scheduler_2 (torch.optim.lr_scheduler): Schedulers for learning rate adjustment.\n",
    "    - factor (float): Parameter influencing data augmentation or pattern generation.\n",
    "    - meta (bool): Flag indicating the use of meta-learning strategies.\n",
    "\n",
    "    Returns:\n",
    "    Tuple containing updated networks and epoch-wise loss records.\n",
    "\n",
    "    \"\"\"\n",
    "    def get_num_args(func):\n",
    "      return func.__code__.co_argcount\n",
    "\n",
    "    max_values_output_first_order = []\n",
    "    max_indices_output_first_order = []\n",
    "    max_values_patterns_tensor = []\n",
    "    max_indices_patterns_tensor = []\n",
    "\n",
    "    epoch_1_order = np.zeros(n_epochs)\n",
    "    epoch_2_order = np.zeros(n_epochs)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # Generate training patterns and targets for each epoch\n",
    "        patterns_tensor, stim_present_tensor, stim_absent_tensor, order_2_tensor = generate_patterns(patterns_number, num_units,factor, 0)\n",
    "\n",
    "        # Forward pass through the first-order network\n",
    "        hidden_representation , output_first_order = first_order_network(patterns_tensor)\n",
    "\n",
    "        patterns_tensor=patterns_tensor.requires_grad_(True)\n",
    "        output_first_order=output_first_order.requires_grad_(True)\n",
    "\n",
    "        # Get max values and indices for output_first_order\n",
    "        max_vals_out, max_inds_out = torch.max(output_first_order[100:], dim=1)\n",
    "        max_inds_out[max_vals_out == 0] = 0\n",
    "        max_values_output_first_order.append(max_vals_out.tolist())\n",
    "        max_indices_output_first_order.append(max_inds_out.tolist())\n",
    "\n",
    "        # Get max values and indices for patterns_tensor\n",
    "        max_vals_pat, max_inds_pat = torch.max(patterns_tensor[100:], dim=1)\n",
    "        max_inds_pat[max_vals_pat == 0] = 0\n",
    "        max_values_patterns_tensor.append(max_vals_pat.tolist())\n",
    "        max_indices_patterns_tensor.append(max_inds_pat.tolist())\n",
    "\n",
    "        optimizer_1.zero_grad()\n",
    "\n",
    "        # Conditionally execute the second-order network pass and related operations\n",
    "        if meta:\n",
    "\n",
    "            # Forward pass through the second-order network with inputs from the first-order network\n",
    "            output_second_order = second_order_network(patterns_tensor, output_first_order)\n",
    "\n",
    "            # Calculate the loss for the second-order network (wagering decision based on comparison)\n",
    "            loss_2 = criterion_2(output_second_order.squeeze(), order_2_tensor[:, 0])\n",
    "\n",
    "            optimizer_2.zero_grad()\n",
    "\n",
    "\n",
    "            # Backpropagate the second-order network's loss\n",
    "            loss_2.backward(retain_graph=True)  # Allows further backpropagation for loss_1 after loss_2\n",
    "\n",
    "            # Update second-order network weights\n",
    "            optimizer_2.step()\n",
    "\n",
    "            scheduler_2.step()\n",
    "\n",
    "            epoch_2_order[epoch] = loss_2.item()\n",
    "        else:\n",
    "            # Skip computations for the second-order network\n",
    "            with torch.no_grad():\n",
    "                # Potentially forward pass through the second-order network without tracking gradients\n",
    "                output_second_order = second_order_network(patterns_tensor, output_first_order)\n",
    "\n",
    "        # Calculate the loss for the first-order network (accuracy of stimulus representation)\n",
    "\n",
    "        num_args = get_num_args(criterion_1)\n",
    "\n",
    "        if num_args == 2:\n",
    "          loss_1 = criterion_1(  output_first_order , stim_present_tensor )\n",
    "        else:\n",
    "          W = first_order_network.state_dict()['fc1.weight']\n",
    "          loss_1 = criterion_1( W, stim_present_tensor.view(-1, 100), output_first_order,\n",
    "                             hidden_representation, lam )\n",
    "\n",
    "        # Backpropagate the first-order network's loss\n",
    "        loss_1.backward()\n",
    "\n",
    "        # Update first-order network weights\n",
    "        optimizer_1.step()\n",
    "\n",
    "        # Reset first-order optimizer gradients to zero for the next iteration\n",
    "\n",
    "        # Update the first-order scheduler\n",
    "        scheduler_1.step()\n",
    "\n",
    "        epoch_1_order[epoch] = loss_1.item()\n",
    "        #epoch_1_order[epoch] = loss_location.item()\n",
    "\n",
    "    return first_order_network, second_order_network, epoch_1_order, epoch_2_order , (max_values_output_first_order[-1],\n",
    "            max_indices_output_first_order[-1],\n",
    "            max_values_patterns_tensor[-1],\n",
    "            max_indices_patterns_tensor[-1])\n",
    "\n",
    "# Define the architecture, optimizers, loss functions, and schedulers for pre training\n",
    "seeds=15\n",
    "\n",
    "results_seed=[]\n",
    "discrimination_seed=[]\n",
    "\n",
    "# Hyperparameters\n",
    "optimizer=\"ADAMAX\"\n",
    "hidden=40\n",
    "factor=2\n",
    "gelu=False\n",
    "gam=0.98\n",
    "meta=True\n",
    "stepsize=25\n",
    "\n",
    "for i in range(seeds):\n",
    "  print(f\"Seed {i}\")\n",
    "\n",
    "  # Compare your results with the patterns generate below\n",
    "  initialize_global()\n",
    "\n",
    "  # Prepare networks, loss functions, optimizers, and schedulers for pre-training\n",
    "  first_order_network, second_order_network, criterion_1, criterion_2, optimizer_1, optimizer_2, scheduler_1, scheduler_2 = prepare_pre_training(hidden, factor, gelu, stepsize, gam)\n",
    "\n",
    "  # Conduct pre-training for both the first-order and second-order networks\n",
    "  first_order_network_pre, second_order_network_pre, epoch_1_order, epoch_2_order , max_value_indices = pre_train(first_order_network, second_order_network, criterion_1,  criterion_2, optimizer_1, optimizer_2, scheduler_1, scheduler_2, factor, meta)\n",
    "\n",
    "  # Plot the training progress of both networks to visualize performance and learning trends\n",
    "  pre_train_plots(epoch_1_order, epoch_2_order, f\"1st & 2nd Order Networks - Seed {i}\" , max_value_indices )\n",
    "\n",
    "  # Configuration step for the main training phase or evaluation\n",
    "  testing_patterns, n_samples = get_test_patterns(factor)\n",
    "\n",
    "  # Function to test the model using the configured testing patterns\n",
    "  first_order_network_pre.eval()\n",
    "  second_order_network_pre.eval()\n",
    "  f1_scores_wager, mse_losses_indices , mse_losses_values , discrimination_performances, results_for_plotting = testing(testing_patterns, n_samples, first_order_network_pre, second_order_network_pre,factor)\n",
    "  results_seed.append(results_for_plotting)\n",
    "  discrimination_seed.append(discrimination_performances)\n",
    "\n",
    "plot_testing(results_seed, discrimination_seed, seeds, \"Test Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2047ee8a-4ebc-41dc-a77a-4e17f7c74947",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Discussion point\n",
    "\n",
    "Let's dive into the outcomes!\n",
    "\n",
    "- Did you notice any variations between the two models?\n",
    "- Can you explain how these differences influenced the performance?\n",
    "- What role does a second-order network play, and in which situations would it be more effective?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55115815-beb2-4f19-a598-9b129ff87637",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Discussion_Point_Second_Order_Network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a880a9-a069-4e0f-a481-f3b85b6a3952",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 1: Second Order Network\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', 'lHRP14mxXv8'), ('Bilibili', 'BV1jM4m1S7ek')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a54d67b-507e-4a8a-9715-0aacdeb06f26",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Video_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a694f1e-3f32-48fc-bce8-0b544d43ca62",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Coding Exercise 3: Plot Surfaces for Content / Awareness Inference\n",
    "\n",
    "To explore the properties of the HOSS model, we can simulate inference at different levels of the hierarchy over the full 2D space of possible input X's. The left panel below shows that the probability of awareness (of any stimulus contents) rises in a graded manner from the lower left corner of the graph (low activation of any feature) to the upper right (high activation of both features). In contrast, the right panel shows that confidence in making a discrimination response (e.g. rightward vs. leftward) increases away from the major diagonal, as the model becomes sure that the sample was generated by either a leftward or rightward tilted stimulus.\n",
    "\n",
    "Together, the two surfaces make predictions about the relationships we might see between discrimination confidence and awareness in a simple psychophysics experiment. One notable prediction is that discrimination could still be possible - and lead to some degree of confidence - even when the higher-order node is \"reporting\" unawareness of the stimulus.\n",
    "\n",
    "Now, let's get hands on and plot those auto-generated patterns!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31503073-a7c0-4502-8d94-5ffa47a22926",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Define the grid\n",
    "xgrid = np.arange(0, 2.01, 0.01)\n",
    "\n",
    "# Define the means for the Gaussian distributions\n",
    "mu = np.array([[0.5, 0.5], [0.5, 1.5], [1.5, 0.5]])\n",
    "\n",
    "# Define the covariance matrix\n",
    "Sigma = np.array([[1, 0], [0, 1]])\n",
    "\n",
    "# Prior probabilities\n",
    "Wprior = np.array([0.5, 0.5])\n",
    "Aprior = 0.5\n",
    "\n",
    "# Initialize arrays to hold confidence and posterior probability\n",
    "confW = np.zeros((len(xgrid), len(xgrid)))\n",
    "posteriorAware = np.zeros((len(xgrid), len(xgrid)))\n",
    "KL_w = np.zeros((len(xgrid), len(xgrid)))\n",
    "KL_A = np.zeros((len(xgrid), len(xgrid)))\n",
    "\n",
    "# Compute confidence and posterior probability for each point in the grid\n",
    "for i, xi in tqdm(enumerate(xgrid), total=len(xgrid), desc='Outer Loop'):\n",
    "    for j, xj in enumerate(xgrid):\n",
    "        X = [xi, xj]\n",
    "        post_w, post_A, KL_w[i, j], KL_A[i, j] = HOSS_evaluate(X, mu, Sigma, Aprior, Wprior)\n",
    "        confW[i, j] = max(post_w[1], post_w[2])\n",
    "        posteriorAware[i, j] = post_A[1]\n",
    "\n",
    "with plt.xkcd():\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Posterior probability \"seen\"\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.contourf(xgrid, xgrid, posteriorAware.T)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('X1')\n",
    "    plt.ylabel('X2')\n",
    "    plt.title('Posterior probability \"seen\"')\n",
    "    plt.axis('square')\n",
    "\n",
    "    # Confidence in identity\n",
    "    plt.subplot(1, 2, 2)\n",
    "    contour_set = plt.contourf(xgrid, xgrid, confW.T)\n",
    "    plt.colorbar()\n",
    "    plt.contour(xgrid, xgrid, posteriorAware.T, levels=[0.5], linewidths=4, colors=['white'])  # Line contour for threshold\n",
    "    plt.xlabel('X1')\n",
    "    plt.ylabel('X2')\n",
    "    plt.title('Confidence in identity')\n",
    "    plt.axis('square')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d129657-62aa-42d1-970a-93fd67736b69",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Simulate KL-divergence surfaces\n",
    "\n",
    "We can also simulate KL-divergences (a measure of Bayesian surprise) at each layer in the network, which under predictive coding models of the brain, has been proposed to scale with neural activation (e.g., Friston, 2005; Summerfield & de Lange, 2014)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66044263-c8de-49a9-a56b-2e7336cc737c",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Define the grid\n",
    "xgrid = np.arange(0, 2.01, 0.01)\n",
    "\n",
    "# Define the means for the Gaussian distributions\n",
    "mu = np.array([[0.5, 0.5], [0.5, 1.5], [1.5, 0.5]])\n",
    "\n",
    "# Define the covariance matrix\n",
    "Sigma = np.array([[1, 0], [0, 1]])\n",
    "\n",
    "# Prior probabilities\n",
    "Wprior = np.array([0.5, 0.5])\n",
    "Aprior = 0.5\n",
    "\n",
    "# Initialize arrays to hold confidence and posterior probability\n",
    "confW = np.zeros((len(xgrid), len(xgrid)))\n",
    "posteriorAware = np.zeros((len(xgrid), len(xgrid)))\n",
    "KL_w = np.zeros((len(xgrid), len(xgrid)))\n",
    "KL_A = np.zeros((len(xgrid), len(xgrid)))\n",
    "\n",
    "# Compute confidence and posterior probability for each point in the grid\n",
    "for i, xi in enumerate(xgrid):\n",
    "    for j, xj in enumerate(xgrid):\n",
    "        X = [xi, xj]\n",
    "        post_w, post_A, KL_w[i, j], KL_A[i, j] = HOSS_evaluate(X, mu, Sigma, Aprior, Wprior)\n",
    "\n",
    "        confW[i, j] = max(post_w[1], post_w[2])\n",
    "        posteriorAware[i, j] = post_A[1]\n",
    "\n",
    "# Calculate the mean K-L divergence for absent and present awareness states\n",
    "KL_A_absent = np.mean(KL_A[posteriorAware < 0.5])\n",
    "KL_A_present = np.mean(KL_A[posteriorAware >= 0.5])\n",
    "KL_w_absent = np.mean(KL_w[posteriorAware < 0.5])\n",
    "KL_w_present = np.mean(KL_w[posteriorAware >= 0.5])\n",
    "\n",
    "with plt.xkcd():\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(18, 6))\n",
    "\n",
    "    # K-L divergence, perceptual states\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.contourf(xgrid, xgrid, KL_w.T, cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('X1')\n",
    "    plt.ylabel('X2')\n",
    "    plt.title('KL-divergence, perceptual states')\n",
    "    plt.axis('square')\n",
    "\n",
    "    # K-L divergence, awareness state\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.contourf(xgrid, xgrid, KL_A.T, cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('X1')\n",
    "    plt.ylabel('X2')\n",
    "    plt.title('KL-divergence, awareness state')\n",
    "    plt.axis('square')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32e4908-0f6f-4259-832f-045adcb19700",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Discussion point\n",
    "\n",
    "Can you recognise the difference between the KL divergence for the W-level and the one for the A-level?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8deb66-9a1d-49e1-a3ef-96970efa8d97",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# to_remove explanation\n",
    "\"\"\"\n",
    "At the level of perceptual states W, there is a substantial asymmetry in the KL-divergence expected when the\n",
    "model says ‘seen’ vs. ‘unseen’ (lefthand panel). This is due to the large belief updates invoked in the\n",
    "perceptual layer W by samples that deviate from the lower lefthand corner - from absence. In contrast, when\n",
    "we compute KL-divergence for the A-level (righthand panel), the level of prediction error is symmetric across\n",
    "seen and unseen decisions, leading to \"hot\" zones both at the upper righthand (present) and lower lefthand\n",
    "(absent) corners of the 2D space.\n",
    "\n",
    "Intuitively, this means that at the W-level, there's a noticeable difference in the KL-divergence values\n",
    "between \"seen\" and \"unseen\" predictions. This large difference is mainly due to significant updates in the\n",
    "model's beliefs at this level when the detected samples are far from what is expected under the condition of\n",
    "\"absence.\" However, when we analyze the K-L divergence at the A-level, the discrepancies in prediction errors\n",
    "between \"seen\" and \"unseen\" are balanced. This creates equally strong responses in the model, whether something\n",
    "is detected or not detected.\n",
    "\n",
    "We can also sort the KL-divergences as a function of whether the model \"reported\" presence or absence. As\n",
    "can be seen in the bar plots below, there is more asymmetry in the prediction error at the W compared to the\n",
    "A levels.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869fc8f1-4199-4525-80b3-26e74babc66a",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "with plt.xkcd():\n",
    "\n",
    "    # Create figure with specified size\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # KL divergence for W states\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.bar(['unseen', 'seen'], [KL_w_absent, KL_w_present], color='k')\n",
    "    plt.ylabel('KL divergence, W states')\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "\n",
    "    # KL divergence for A states\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.bar(['unseen', 'seen'], [KL_A_absent, KL_A_present], color='k')\n",
    "    plt.ylabel('KL divergence, A states')\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ecb92c-bfe3-4e49-bd40-f11ffa685ece",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_HOSS_Bonus_Content\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd87344-d473-44af-a881-b68e5471d353",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Discussion\n",
    "This section contains an extra discussion exercise if you have time and inclination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca33829c-8d54-437e-ba33-d3003af51d7a",
   "metadata": {
    "execution": {}
   },
   "source": [
    "In this bonus section, Megan and Anil will delve into the complexities of defining and testing for consciousness, particularly in the context of artificial intelligence. We will explore various theoretical perspectives, examine classic and contemporary tests for consciousness, and discuss the challenges and ethical implications of determining whether a system truly possesses conscious experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b621ea-1639-4131-8ec3-9cdf34a64f77",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Video 2: Consciousness Bonus Content\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "video_ids = [('Youtube', '00dL8q7WgcU'), ('Bilibili', 'BV12n4y1Q7C2')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c202fb-f580-4a96-8f8e-bad24ed1d55c",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Video_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e839f2-e237-4ed4-9045-56dc7b5f6d60",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Discussion activity: Is it actually conscious?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2720c0b5-6386-43a6-9647-f1245531c376",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We discussed the difference between these two...\n",
    "- \"Forward\" tests: passing means the machine is conscious (or intelligent).\n",
    "- \"Reverse\" tests: passing means humans are convinced that a machine is conscious (or intelligent).\n",
    "\n",
    "**Discuss!** If a system (AI, other animal, other human) exhibited all the \"right signs\" of being conscious, how can we know for sure it is actually conscious? How could you design a test to be a true forward test?\n",
    "\n",
    "- Room 1: I think you could design a forward test in this way... [share your ideas]\n",
    "- Room 2: I think a forward test is impossible, and here's why [share your ideas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84958157-c165-4cc3-be76-408999cf44ad",
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_Discussion_activity\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "W2D5_Tutorial1",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
